# lightning.pytorch==2.5.5
seed_everything: 42
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: null
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      name: AnoDDPM
      save_dir: .
      version: null
      offline: true
      dir: null
      id: null
      anonymous: null
      project: StrokeFormer
      log_model: false
      experiment: null
      prefix: ''
      checkpoint_name: null
      entity: neurone-lab
      notes: null
      tags: null
      config: null
      config_exclude_keys: null
      config_include_keys: null
      allow_val_change: null
      group: anoddpm
      job_type: null
      mode: null
      force: null
      reinit: null
      resume: null
      resume_from: null
      fork_from: null
      save_code: null
      tensorboard: null
      sync_tensorboard: null
      monitor_gym: null
      settings: null
  callbacks: null
  fast_dev_run: false
  max_epochs: null
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: null
  log_every_n_steps: null
  enable_checkpointing: null
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null
  model_registry: null
model:
  img_size:
    - 256
    - 256
  base_channels: 128
  conv_resample: true
  num_classes: 2
  n_heads: 1
  n_head_channels: -1
  channel_mults: ''
  num_res_blocks: 2
  dropout: 0
  attention_resolutions: 32,16,8
  biggan_updown: true
  in_channels: 1
  diff_betas: null
  beta_schedule: linear
  train_start: false
  T: 1000
  diff_loss_type: l2
  diff_loss_weight: null
  diff_noise: gauss
  lr: 0.0001
  weight_decay: 0.0
  betas:
  - 0.9
  - 0.999
data:
  paths:
    train:
      masks: data/ATLAS_2/Processed/Masks
      scans: data/ATLAS_2/Processed/Scans
    val:
      masks: data/ATLAS_2/Processed/Masks
      scans: data/ATLAS_2/Processed/Scans
  num_classes: 2
  ext: .npy
  slice_stride: 1
  slices_per_scan: 1
  scan_dim:
  - 1
  - 189
  - 192
  - 192
  resize_to:
    - 256
    - 256
  transforms: null
  augment: false
  batch_size: 1
  num_workers: 0
optimizer: null
lr_scheduler: null
ckpt_path: null
